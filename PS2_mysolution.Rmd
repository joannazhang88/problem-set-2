---
title: "PS2"
author: "Joanna Zhang"
date: "1/31/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = F, message = F)
library(tidyverse)
library(rcfss)
library(broom)
library(rsample)
library(yardstick)
library(dplyr)
```
## 1.
```{r}
nesdata <- read.csv("nes2008.csv")
nes_mod <- lm(biden ~ female + age + educ + rep + dem,data = nesdata)
knitr::kable(tidy(nes_mod))
modmse <- augment(nes_mod, newdata = nesdata) %>% 
  mse(truth = biden, estimate = .fitted) 
knitr::kable(modmse)
```

The regression results and the estimated MSE are in the tables above. We see that all the independent variables are significant at a 10% level. The model generates a MSE of 395.27, which means that on average, the squared distance between the actual values and the predicted values is 395.27. This implies that our model may not be very accurate in predicting values, since the feeling thermometer only ranges from 0 to 100, a squared error of about 400 is pretty large.


## 2.a
```{r}
set.seed(123)
nes_split <- initial_split(data = nesdata, prop = 0.5)
nes_train <- training(nes_split)
nes_test <- testing(nes_split)
```

## 2.b
```{r}
nes_mod_train <- lm(biden ~ female + age + educ + rep + dem, data = nes_train)
tidy(nes_mod_train)
```

## 2.c
```{r}
testmse <- augment(nes_mod_train, newdata = nes_test) %>%
  mse(truth = biden, estimate = .fitted)
knitr::kable(testmse)
```

## 2.d
The MSE of the model using a simple holdout validation approach is 392.38. Compared to the MSE in question 1 (395), this MSE is slightly lower, but there is no big difference between the two. The reason why we do not see an improvenent in the MSE here is probabily that we are not applying any treatment to our sample. Alghough we split the data in to a  test set and a training set, the distribution of the observations in the sample does not change. We still get a model that has about the sampe accuracy as in question 1.


## 3.
```{r}
set.seed(234)
mse_thousand <- list()
for (i in 1:1000){
  nes_split_i <- initial_split(data = nesdata, prop = 0.5)
  nes_train_i <- training(nes_split_i)
  nes_test_i <- testing(nes_split_i)
  mod_i <- lm(biden ~ female + age + educ + rep + dem, data = nes_train_i)
  mse_i<-augment(mod_i, newdata = nes_test_i) %>%
    mse(truth = biden, estimate = .fitted) 
  mse_thousand<- c(mse_thousand, mse_i[[3]])
}
msedf <- data.frame(matrix(mse_thousand))
names(msedf)[1] <- "MSE"
msedf$MSE <- as.numeric(msedf$MSE)
  
msedf %>% 
  ggplot(aes(x = MSE)) +
  geom_histogram(aes(y=..density..),color = "black", fill = "white")+
  geom_density(alpha=0.2, fill="#FF6666")+
  theme_minimal()+
  labs(title = "Distribution of MSEs", x = "MSE", y = "Density")
```


```{r}
tidy(nes_mod)

lm_coefs <- function(splits, ...) {
  ## use `analysis` or `as.data.frame` to get the analysis data
  mod <- lm(biden ~ female + age + educ + rep + dem, data = analysis(splits))
  tidy(mod)
}

nes_all <- nesdata %>%
  bootstraps(1000) %>%
  mutate(coef = map(splits, lm_coefs))

nes_all%>%
  unnest(coef) %>%
  group_by(term) %>%
  summarize(.estimate = mean(estimate),
            .se = sd(estimate, na.rm = TRUE))

```

